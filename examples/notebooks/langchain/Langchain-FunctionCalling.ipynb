{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766aaa81-96e6-42dc-b29d-8216d2a7feec",
   "metadata": {},
   "source": [
    "## Function Calling / Tool Calling with vLLM\n",
    "\n",
    "In this notebook, we will explore how the LLM can use external tools to enhance its capabilities. We'll begin by adding and configuring a search tool to allow the LLM to perform real-time searches.\n",
    "\n",
    "By the end of this notebook, you'll be able to integrate and configure external search tools with a language model, and use them to perform real-time searches and enhance responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a64c9c-bc7a-4de3-8a11-d9ba805298a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Used: Granite-3.1(8B) with Function Calling enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0022f3fb-ee50-40f2-b276-b8194668e49e",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6210f6d4-0375-486e-ba37-8c25c5f18f10",
   "metadata": {},
   "source": [
    "#### Installing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a16ed2e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain openai \"langchain-core==0.3.27\" termcolor langchain_community duckduckgo_search wikipedia langchain_experimental langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60bb3f0f-40b5-49a6-b493-5e361db0113e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import VLLMOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from typing import Annotated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236cf3c2-f98d-4026-8232-72dab2ca7dcb",
   "metadata": {},
   "source": [
    "## 2. DuckDuckGo Search Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240fd72-f910-4ba4-82dc-c5ebf278452b",
   "metadata": {
    "tags": []
   },
   "source": [
    "First, we will configure the tool by initializing the DuckDuckGo search functionality. This will be the primary tool for real-time search queries in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d7998b5-4373-4b70-bd81-9617f7ff6bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Initialize DuckDuckGo Search Tool\n",
    "duckduckgo_search = DuckDuckGoSearchRun()\n",
    "\n",
    "# Adding the search tool to the list of available tools\n",
    "tools = [duckduckgo_search]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f8179d-9841-45b0-b123-f62ae9fa5fa2",
   "metadata": {},
   "source": [
    "Render the tool’s description and ensures it is formatted correctly for integration into the LLM's prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee09847d-9ff7-4181-ad11-96186bf0a322",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools Name:\n",
      " duckduckgo_search\n",
      "Tools Description:\n",
      " duckduckgo_search - A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query., args: {{'query': {{'description': 'search query to look up', 'title': 'Query', 'type': 'string'}}}}\n"
     ]
    }
   ],
   "source": [
    "# Render tool description to ensure it's ready for LLM usage\n",
    "from langchain.tools.render import render_text_description_and_args\n",
    "\n",
    "tools_name = duckduckgo_search.name\n",
    "\n",
    "tools_description = (\n",
    "    render_text_description_and_args(tools).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    ")\n",
    "print(\"Tools Name:\\n\", tools_name)\n",
    "print(\"Tools Description:\\n\", tools_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484b7c62-ea7d-4fd3-adcf-847beee5c0fb",
   "metadata": {},
   "source": [
    "## 3. Model Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94bf848-656e-49ee-bc1e-7c4d2474678d",
   "metadata": {},
   "source": [
    "#### Define the Inference Model Server specifics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b908fd0-01dd-4ad2-b745-b3a4c56a7a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INFERENCE_SERVER_URL = os.getenv('API_URL_GRANITE')\n",
    "MODEL_NAME = \"granite-3-8b-instruct\"\n",
    "API_KEY= os.getenv('API_KEY_GRANITE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b2f3f-ac23-4531-984b-6e8357233992",
   "metadata": {},
   "source": [
    "#### Create the LLM instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01baa2b8-529d-455d-ad39-ef4a96dbaf97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LLM definition\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_api_base= f\"{INFERENCE_SERVER_URL}/v1\",\n",
    "    model_name=MODEL_NAME,\n",
    "    top_p=0.92,\n",
    "    temperature=0.01,\n",
    "    max_tokens=512,\n",
    "    presence_penalty=1.03,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e949f162-8713-4f1e-bea9-f55dba2e5c74",
   "metadata": {},
   "source": [
    "# 4. Tool Calling\n",
    "\n",
    "Tool calling enables a chat model to generate structured output by \"calling a tool\" in response to a prompt.\n",
    "\n",
    "It’s important to note that the model itself doesn’t execute the tool, it only generates the arguments needed for the tool. Running the tool, or deciding not to, is entirely up to the user.\n",
    "\n",
    "This technique is versatile and can be used even when no tools are actually invoked. LangChain provides standard interfaces for defining tools, integrating them with LLMs, and managing tool calls seamlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a97e9afc-5d13-4232-95dc-d80a8a3fd6ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools, tool_choice=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36836ede-5f22-4711-b77a-7717026d68ff",
   "metadata": {},
   "source": [
    "For a model to be able to call tools, we need to pass in tool schemas that describe what the tool does and what it's arguments are. Chat models that support tool calling features implement a .bind_tools() method for passing tool schemas to the model.\n",
    "The tool_choice in the bind_tools() defines which tool to require the model to call, and \"auto\" automatically selects a tool (including no tool if it's not needed)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72a00b6-b04a-4540-aba5-b2c0e660a61f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Passing tool outputs to chat models\n",
    "\n",
    "Now, let's get the model to call a tool. We'll add it to a list of messages that we'll treat as conversation history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f220d37b-2a99-4a62-a47e-8fe490035406",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'duckduckgo_search', 'args': {'query': 'latest version of OpenShift'}, 'id': 'chatcmpl-tool-bba88a9c934c420e8509a4c5e8f959f6', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"Search what is the latest version of OpenShift?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "\n",
    "messages.append(ai_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0166f82e-6d64-427b-b705-17874777dfbd",
   "metadata": {},
   "source": [
    "As you can see the type of message is a \"tool_call\", and includes the name of the tool used (duckduckgo_search) and the query included in the message as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e5c091-5a3b-47f3-8808-dd996e4dab9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next, let's use the arguments generated by the model to invoke the tool functions!\n",
    "\n",
    "With LangChain, invoking a tool using a ToolCall automatically returns a ToolMessage, which can then be seamlessly passed back to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7ed16cc-c40c-4ea5-9462-8b2529027da6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/langchain_community/utilities/duckduckgo_search.py:64: UserWarning: backend='api' is deprecated, using backend='auto'\n",
      "  ddgs_gen = ddgs.text(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Search what is the latest version of OpenShift?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'chatcmpl-tool-bba88a9c934c420e8509a4c5e8f959f6', 'function': {'arguments': '{\"query\": \"latest version of OpenShift\"}', 'name': 'duckduckgo_search'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'granite30-8b'}, id='run-641a2bf1-ed1a-452b-8c64-c1d75d999e0c-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'latest version of OpenShift'}, 'id': 'chatcmpl-tool-bba88a9c934c420e8509a4c5e8f959f6', 'type': 'tool_call'}]),\n",
       " ToolMessage(content=\"Red Hat OpenShift 4.17 is now generally available. Based on Kubernetes 1.30 and CRI-O 1.30, OpenShift 4.17 features expanded control plane options, increased flexibility for virtualization and networking, new capabilities to leverage generative AI, and continued investment in Red Hat OpenShift Platform Plus.These additions further accelerate innovation with OpenShift without compromising on ... The IBM Z® and IBM® LinuxONE release on OpenShift Container Platform 4.17 adds improvements and new capabilities to OpenShift Container Platform components and concepts. This release introduces support for the following features on IBM Z® and IBM® LinuxONE: ... In earlier versions of OpenShift Container Platform, when destroying a cluster ... Updating from an older version to a supported version can be challenging, and in some cases not possible. We recommend you keep your cluster on the latest OpenShift version to avoid potential update issues. For example, if the oldest supported Azure Red Hat OpenShift version is 4.13 and you are on 4.12 or older, you're outside of support. Red Hat provides three different phases of support: Full Support, Maintenance Support and Extended Update Support. The Full Support phase begins at the GA/release of the minor version and ends after a 6 months period OR 90 days after the GA of the superseding minor release, whichever is later. During the Full Support Phase, qualified Critical and Important Security Advisories and Urgent and ... Red Hat OpenShift 4.17 introduces new security features to help organizations focus on innovation without having to compromise on the platform's security posture. ... Red Hat OpenShift 4.17 is now generally available. More information, including how to upgrade to the latest version, is available here. Red Hat OpenShift Lightspeed is now ...\", name='duckduckgo_search', tool_call_id='chatcmpl-tool-bba88a9c934c420e8509a4c5e8f959f6')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"duckduckgo_search\": duckduckgo_search}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6151280e-a177-4d80-bf46-b126aa406c1e",
   "metadata": {},
   "source": [
    "## Final answer after providing the tool result to the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dfedd5-f56c-4de3-a4b1-771a3f9414a1",
   "metadata": {},
   "source": [
    "Finally, we'll provide the tool results to the model. Using this information, the model will generate a final response to the original query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a75eeff3-3f44-4362-ac7a-4c4ca1f5fc9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest version of OpenShift is Red Hat OpenShift 4.17, which was released on [insert date]. This version features expanded control plane options, increased flexibility for virtualization and networking, new capabilities to leverage generative AI, and continued investment in Red Hat OpenShift Platform Plus. It also introduces support for IBM Z® and IBM® LinuxONE release on OpenShift Container Platform 4.17. Red Hat provides three different phases of support: Full Support, Maintenance Support, and Extended Update Support. More information, including how to upgrade to the latest version, is available here."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The latest version of OpenShift is Red Hat OpenShift 4.17, which was released on [insert date]. This version features expanded control plane options, increased flexibility for virtualization and networking, new capabilities to leverage generative AI, and continued investment in Red Hat OpenShift Platform Plus. It also introduces support for IBM Z® and IBM® LinuxONE release on OpenShift Container Platform 4.17. Red Hat provides three different phases of support: Full Support, Maintenance Support, and Extended Update Support. More information, including how to upgrade to the latest version, is available here.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'granite30-8b'}, id='run-f67d738f-bacd-4abe-9a4c-0cbf31474537-0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdae5ff-8e42-4ede-8ac4-5ff988c1cf80",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    " \n",
    "In this notebook, we've successfully extended the capabilities of the LLM by integrating an external tool (DuckDuckGo search). We covered:\n",
    "\n",
    "- **LLM and Tool Integration:** How to modify the system prompt for tool access.\n",
    "- **Tool Setup and Configuration:** Setting up the DuckDuckGo search tool for real-time information retrieval.\n",
    "- **Making Requests and Handling Responses:** Using the tool during LLM interactions and processing the results.\n",
    "\n",
    "With these tools in place, you're now equipped to extend the LLM's capabilities even further by adding more tools and refining its behavior. Happy coding!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
